{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e63a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Priyanshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Data Collection\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd\n",
    "\n",
    "## load the dataset\n",
    "data = gutenberg.raw('carroll-alice.txt')\n",
    "## save to a file\n",
    "with open('alice.txt', 'w') as file:\n",
    "    file.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a398cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2858"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## load the dataset\n",
    "with open('alice.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "## Tokenize the text-creating indexes for words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81fe60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " \"'\": 2,\n",
       " 'and': 3,\n",
       " 'to': 4,\n",
       " 'a': 5,\n",
       " 'she': 6,\n",
       " 'of': 7,\n",
       " 'it': 8,\n",
       " 'said': 9,\n",
       " 'alice': 10,\n",
       " 'in': 11,\n",
       " 'was': 12,\n",
       " 'you': 13,\n",
       " 'i': 14,\n",
       " 'that': 15,\n",
       " 'as': 16,\n",
       " 'her': 17,\n",
       " 'at': 18,\n",
       " 'on': 19,\n",
       " 'with': 20,\n",
       " 'all': 21,\n",
       " 'had': 22,\n",
       " 'be': 23,\n",
       " 'for': 24,\n",
       " 'so': 25,\n",
       " 'very': 26,\n",
       " 'not': 27,\n",
       " 'but': 28,\n",
       " 'this': 29,\n",
       " 'little': 30,\n",
       " \"'i\": 31,\n",
       " 'they': 32,\n",
       " 'out': 33,\n",
       " 'he': 34,\n",
       " 'is': 35,\n",
       " 'down': 36,\n",
       " 'what': 37,\n",
       " 'up': 38,\n",
       " 'one': 39,\n",
       " 'his': 40,\n",
       " 'about': 41,\n",
       " 'them': 42,\n",
       " 'know': 43,\n",
       " 'like': 44,\n",
       " 'were': 45,\n",
       " 'went': 46,\n",
       " 'again': 47,\n",
       " 'herself': 48,\n",
       " 'then': 49,\n",
       " 'would': 50,\n",
       " 'no': 51,\n",
       " 'could': 52,\n",
       " 'have': 53,\n",
       " 'if': 54,\n",
       " 'thought': 55,\n",
       " 'when': 56,\n",
       " 'do': 57,\n",
       " 'or': 58,\n",
       " 'there': 59,\n",
       " 'time': 60,\n",
       " 'queen': 61,\n",
       " 'into': 62,\n",
       " 'see': 63,\n",
       " 'me': 64,\n",
       " 'off': 65,\n",
       " 'king': 66,\n",
       " 'did': 67,\n",
       " 'your': 68,\n",
       " 'by': 69,\n",
       " 'began': 70,\n",
       " 'its': 71,\n",
       " 'turtle': 72,\n",
       " \"'and\": 73,\n",
       " 'way': 74,\n",
       " 'an': 75,\n",
       " 'my': 76,\n",
       " 'mock': 77,\n",
       " 'quite': 78,\n",
       " 'who': 79,\n",
       " \"don't\": 80,\n",
       " 'hatter': 81,\n",
       " 'gryphon': 82,\n",
       " 'think': 83,\n",
       " 'how': 84,\n",
       " 'much': 85,\n",
       " 'say': 86,\n",
       " 'their': 87,\n",
       " 'some': 88,\n",
       " 'first': 89,\n",
       " 'now': 90,\n",
       " 'just': 91,\n",
       " 'head': 92,\n",
       " 'thing': 93,\n",
       " 'more': 94,\n",
       " 'here': 95,\n",
       " 'go': 96,\n",
       " 'voice': 97,\n",
       " 'are': 98,\n",
       " 'rabbit': 99,\n",
       " 'only': 100,\n",
       " 'looked': 101,\n",
       " 'never': 102,\n",
       " 'which': 103,\n",
       " 'got': 104,\n",
       " 'get': 105,\n",
       " 'must': 106,\n",
       " 'him': 107,\n",
       " 'mouse': 108,\n",
       " 'after': 109,\n",
       " 'such': 110,\n",
       " 'round': 111,\n",
       " 'well': 112,\n",
       " 'over': 113,\n",
       " 'came': 114,\n",
       " 'other': 115,\n",
       " \"'you\": 116,\n",
       " 'tone': 117,\n",
       " 'great': 118,\n",
       " \"i'm\": 119,\n",
       " \"'but\": 120,\n",
       " 'duchess': 121,\n",
       " 'dormouse': 122,\n",
       " 'before': 123,\n",
       " 'been': 124,\n",
       " 'any': 125,\n",
       " 'back': 126,\n",
       " 'two': 127,\n",
       " 'from': 128,\n",
       " 'cat': 129,\n",
       " \"'what\": 130,\n",
       " 'can': 131,\n",
       " 'march': 132,\n",
       " 'large': 133,\n",
       " \"it's\": 134,\n",
       " 'will': 135,\n",
       " 'last': 136,\n",
       " 'once': 137,\n",
       " 'long': 138,\n",
       " 'looking': 139,\n",
       " 'put': 140,\n",
       " 'come': 141,\n",
       " 'things': 142,\n",
       " 'right': 143,\n",
       " 'hare': 144,\n",
       " 'nothing': 145,\n",
       " 'made': 146,\n",
       " 'white': 147,\n",
       " 'found': 148,\n",
       " 'next': 149,\n",
       " 'door': 150,\n",
       " \"'it\": 151,\n",
       " 'heard': 152,\n",
       " 'day': 153,\n",
       " 'eyes': 154,\n",
       " 'moment': 155,\n",
       " 'tell': 156,\n",
       " 'replied': 157,\n",
       " 'dear': 158,\n",
       " 'look': 159,\n",
       " 'might': 160,\n",
       " 'seemed': 161,\n",
       " 'going': 162,\n",
       " 'make': 163,\n",
       " 'good': 164,\n",
       " 'should': 165,\n",
       " 'three': 166,\n",
       " \"can't\": 167,\n",
       " 'caterpillar': 168,\n",
       " 'too': 169,\n",
       " 'upon': 170,\n",
       " 'poor': 171,\n",
       " \"i'll\": 172,\n",
       " 'course': 173,\n",
       " 'rather': 174,\n",
       " 'soon': 175,\n",
       " 'away': 176,\n",
       " 'without': 177,\n",
       " 'while': 178,\n",
       " 'yet': 179,\n",
       " 'took': 180,\n",
       " \"'it's\": 181,\n",
       " \"'oh\": 182,\n",
       " 'shall': 183,\n",
       " \"'well\": 184,\n",
       " 'felt': 185,\n",
       " 'than': 186,\n",
       " 'half': 187,\n",
       " 'same': 188,\n",
       " \"won't\": 189,\n",
       " 'added': 190,\n",
       " 'getting': 191,\n",
       " 'oh': 192,\n",
       " 'another': 193,\n",
       " \"'why\": 194,\n",
       " 'words': 195,\n",
       " 'wish': 196,\n",
       " 'ever': 197,\n",
       " 'find': 198,\n",
       " 'minute': 199,\n",
       " \"'if\": 200,\n",
       " \"'the\": 201,\n",
       " 'jury': 202,\n",
       " 'take': 203,\n",
       " \"i've\": 204,\n",
       " 'sort': 205,\n",
       " 'hand': 206,\n",
       " 'cried': 207,\n",
       " 'sure': 208,\n",
       " \"'i'm\": 209,\n",
       " 'feet': 210,\n",
       " 'tried': 211,\n",
       " 'anything': 212,\n",
       " 'even': 213,\n",
       " 'tea': 214,\n",
       " 'however': 215,\n",
       " 'curious': 216,\n",
       " 'being': 217,\n",
       " 'till': 218,\n",
       " 'we': 219,\n",
       " 'old': 220,\n",
       " 'use': 221,\n",
       " 'wonder': 222,\n",
       " 'why': 223,\n",
       " 'house': 224,\n",
       " \"that's\": 225,\n",
       " 'table': 226,\n",
       " 'enough': 227,\n",
       " 'something': 228,\n",
       " 'soup': 229,\n",
       " 'court': 230,\n",
       " 'end': 231,\n",
       " 'spoke': 232,\n",
       " \"you're\": 233,\n",
       " 'eat': 234,\n",
       " 'question': 235,\n",
       " 'side': 236,\n",
       " 'sat': 237,\n",
       " \"there's\": 238,\n",
       " 'asked': 239,\n",
       " 'ran': 240,\n",
       " 'under': 241,\n",
       " 'talking': 242,\n",
       " 'bit': 243,\n",
       " 'turned': 244,\n",
       " 'high': 245,\n",
       " 'garden': 246,\n",
       " 'indeed': 247,\n",
       " 'hastily': 248,\n",
       " \"doesn't\": 249,\n",
       " \"'how\": 250,\n",
       " \"'that's\": 251,\n",
       " 'seen': 252,\n",
       " 'near': 253,\n",
       " 'idea': 254,\n",
       " 'please': 255,\n",
       " 'air': 256,\n",
       " 'saying': 257,\n",
       " 'low': 258,\n",
       " 'face': 259,\n",
       " \"'come\": 260,\n",
       " 'gave': 261,\n",
       " 'am': 262,\n",
       " 'done': 263,\n",
       " \"'that\": 264,\n",
       " 'called': 265,\n",
       " 'arm': 266,\n",
       " 'mad': 267,\n",
       " 'beginning': 268,\n",
       " 'hear': 269,\n",
       " 'itself': 270,\n",
       " 'ought': 271,\n",
       " 'saw': 272,\n",
       " 'let': 273,\n",
       " 'through': 274,\n",
       " \"didn't\": 275,\n",
       " 'perhaps': 276,\n",
       " 'remember': 277,\n",
       " 'trying': 278,\n",
       " 'left': 279,\n",
       " 'anxiously': 280,\n",
       " 'set': 281,\n",
       " 'knew': 282,\n",
       " 'these': 283,\n",
       " 'sea': 284,\n",
       " 'talk': 285,\n",
       " 'us': 286,\n",
       " 'both': 287,\n",
       " \"'i've\": 288,\n",
       " 'baby': 289,\n",
       " 'suddenly': 290,\n",
       " 'close': 291,\n",
       " 'still': 292,\n",
       " 'people': 293,\n",
       " 'cats': 294,\n",
       " 'behind': 295,\n",
       " 'certainly': 296,\n",
       " \"'no\": 297,\n",
       " 'size': 298,\n",
       " 'grow': 299,\n",
       " 'speak': 300,\n",
       " 'far': 301,\n",
       " 'kept': 302,\n",
       " 'used': 303,\n",
       " 'change': 304,\n",
       " 'always': 305,\n",
       " 'dodo': 306,\n",
       " 'whole': 307,\n",
       " 'bill': 308,\n",
       " 'better': 309,\n",
       " 'room': 310,\n",
       " 'gone': 311,\n",
       " 'footman': 312,\n",
       " 'cook': 313,\n",
       " 'dance': 314,\n",
       " \"alice's\": 315,\n",
       " 'chapter': 316,\n",
       " \"wouldn't\": 317,\n",
       " 'many': 318,\n",
       " 'among': 319,\n",
       " 'afraid': 320,\n",
       " 'every': 321,\n",
       " 'begin': 322,\n",
       " 'because': 323,\n",
       " 'finished': 324,\n",
       " 'best': 325,\n",
       " 'game': 326,\n",
       " 'hardly': 327,\n",
       " 'life': 328,\n",
       " 'deal': 329,\n",
       " 'queer': 330,\n",
       " 'everything': 331,\n",
       " 'try': 332,\n",
       " 'hands': 333,\n",
       " 'suppose': 334,\n",
       " 'silence': 335,\n",
       " \"'of\": 336,\n",
       " 'turning': 337,\n",
       " \"'yes\": 338,\n",
       " 'where': 339,\n",
       " \"'then\": 340,\n",
       " 'may': 341,\n",
       " 'pigeon': 342,\n",
       " 'majesty': 343,\n",
       " 'book': 344,\n",
       " 'mind': 345,\n",
       " 'whether': 346,\n",
       " 'hurried': 347,\n",
       " 'though': 348,\n",
       " 'glad': 349,\n",
       " 'ask': 350,\n",
       " 'else': 351,\n",
       " 'dinah': 352,\n",
       " 'hurry': 353,\n",
       " 'waited': 354,\n",
       " 'minutes': 355,\n",
       " 'tears': 356,\n",
       " 'child': 357,\n",
       " 'makes': 358,\n",
       " 'growing': 359,\n",
       " 'pool': 360,\n",
       " \"'a\": 361,\n",
       " 'gloves': 362,\n",
       " \"'not\": 363,\n",
       " \"'we\": 364,\n",
       " \"wasn't\": 365,\n",
       " 'beautiful': 366,\n",
       " 'pig': 367,\n",
       " 'sitting': 368,\n",
       " 'having': 369,\n",
       " 'conversation': 370,\n",
       " 'own': 371,\n",
       " 'lessons': 372,\n",
       " 'heads': 373,\n",
       " 'word': 374,\n",
       " 'name': 375,\n",
       " \"'now\": 376,\n",
       " 'sight': 377,\n",
       " 'walked': 378,\n",
       " 'glass': 379,\n",
       " 'small': 380,\n",
       " 'opened': 381,\n",
       " 'those': 382,\n",
       " 'really': 383,\n",
       " 'bottle': 384,\n",
       " 'read': 385,\n",
       " 'children': 386,\n",
       " 'box': 387,\n",
       " \"'they\": 388,\n",
       " 'foot': 389,\n",
       " 'yourself': 390,\n",
       " 'fan': 391,\n",
       " 'thinking': 392,\n",
       " 'nearly': 393,\n",
       " 'offended': 394,\n",
       " 'birds': 395,\n",
       " 'party': 396,\n",
       " 'rest': 397,\n",
       " 'mean': 398,\n",
       " 'keep': 399,\n",
       " 'mouth': 400,\n",
       " 'repeated': 401,\n",
       " \"they're\": 402,\n",
       " 'remarked': 403,\n",
       " 'remark': 404,\n",
       " 'soldiers': 405,\n",
       " 'witness': 406,\n",
       " 'either': 407,\n",
       " 'coming': 408,\n",
       " \"couldn't\": 409,\n",
       " 'answer': 410,\n",
       " 'matter': 411,\n",
       " 'hall': 412,\n",
       " 'key': 413,\n",
       " 'rate': 414,\n",
       " 'few': 415,\n",
       " 'waiting': 416,\n",
       " 'croquet': 417,\n",
       " 'against': 418,\n",
       " 'want': 419,\n",
       " 'give': 420,\n",
       " 'help': 421,\n",
       " 'different': 422,\n",
       " 'mine': 423,\n",
       " 'tail': 424,\n",
       " 'creatures': 425,\n",
       " 'continued': 426,\n",
       " 'believe': 427,\n",
       " 'angrily': 428,\n",
       " 'shook': 429,\n",
       " 'least': 430,\n",
       " 'reason': 431,\n",
       " 'together': 432,\n",
       " 'shouted': 433,\n",
       " 'turn': 434,\n",
       " 'timidly': 435,\n",
       " 'puzzled': 436,\n",
       " 'butter': 437,\n",
       " 'interrupted': 438,\n",
       " 'knave': 439,\n",
       " 'join': 440,\n",
       " 'sister': 441,\n",
       " 'feel': 442,\n",
       " 'making': 443,\n",
       " 'watch': 444,\n",
       " 'slowly': 445,\n",
       " 'happen': 446,\n",
       " 'noticed': 447,\n",
       " 'top': 448,\n",
       " 'four': 449,\n",
       " 'opportunity': 450,\n",
       " 'distance': 451,\n",
       " 'seem': 452,\n",
       " \"'do\": 453,\n",
       " 'dry': 454,\n",
       " 'bright': 455,\n",
       " 'fact': 456,\n",
       " \"'in\": 457,\n",
       " 'followed': 458,\n",
       " 'lying': 459,\n",
       " 'work': 460,\n",
       " 'ready': 461,\n",
       " 'hard': 462,\n",
       " 'changed': 463,\n",
       " 'five': 464,\n",
       " 'live': 465,\n",
       " 'play': 466,\n",
       " 'beg': 467,\n",
       " 'our': 468,\n",
       " \"you'd\": 469,\n",
       " 'eagerly': 470,\n",
       " 'meaning': 471,\n",
       " 'explain': 472,\n",
       " 'running': 473,\n",
       " 'story': 474,\n",
       " 'window': 475,\n",
       " 'place': 476,\n",
       " 'appeared': 477,\n",
       " 'wood': 478,\n",
       " 'mushroom': 479,\n",
       " \"haven't\": 480,\n",
       " 'most': 481,\n",
       " 'tree': 482,\n",
       " 'fish': 483,\n",
       " 'ground': 484,\n",
       " 'asleep': 485,\n",
       " 'hearts': 486,\n",
       " 'gardeners': 487,\n",
       " \"'off\": 488,\n",
       " 'whiting': 489,\n",
       " 'adventures': 490,\n",
       " 'tired': 491,\n",
       " 'hot': 492,\n",
       " 'pocket': 493,\n",
       " 'world': 494,\n",
       " 'deep': 495,\n",
       " 'fall': 496,\n",
       " 'listen': 497,\n",
       " \"it'll\": 498,\n",
       " 'fancy': 499,\n",
       " 'manage': 500,\n",
       " 'begun': 501,\n",
       " 'dream': 502,\n",
       " 'middle': 503,\n",
       " 'wondering': 504,\n",
       " 'golden': 505,\n",
       " 'open': 506,\n",
       " 'larger': 507,\n",
       " 'happened': 508,\n",
       " 'neck': 509,\n",
       " 'feeling': 510,\n",
       " \"'for\": 511,\n",
       " 'leave': 512,\n",
       " 'generally': 513,\n",
       " 'eye': 514,\n",
       " 'surprised': 515,\n",
       " 'shoes': 516,\n",
       " 'myself': 517,\n",
       " 'kind': 518,\n",
       " 'hair': 519,\n",
       " 'goes': 520,\n",
       " 'learn': 521,\n",
       " 'frightened': 522,\n",
       " 'chin': 523,\n",
       " \"hadn't\": 524,\n",
       " 'william': 525,\n",
       " 'history': 526,\n",
       " \"'as\": 527,\n",
       " \"'are\": 528,\n",
       " 'lory': 529,\n",
       " 'has': 530,\n",
       " 'trial': 531,\n",
       " 'others': 532,\n",
       " \"'he\": 533,\n",
       " \"i'd\": 534,\n",
       " 'stood': 535,\n",
       " 'does': 536,\n",
       " 'grown': 537,\n",
       " 'business': 538,\n",
       " \"'so\": 539,\n",
       " 'trees': 540,\n",
       " 'each': 541,\n",
       " \"isn't\": 542,\n",
       " 'nose': 543,\n",
       " 'serpent': 544,\n",
       " 'draw': 545,\n",
       " 'silent': 546,\n",
       " 'pepper': 547,\n",
       " \"'there's\": 548,\n",
       " 'pleased': 549,\n",
       " 'song': 550,\n",
       " 'bread': 551,\n",
       " 'twinkle': 552,\n",
       " \"queen's\": 553,\n",
       " 'hedgehog': 554,\n",
       " 'moral': 555,\n",
       " 'lobster': 556,\n",
       " 'lobsters': 557,\n",
       " 'oop': 558,\n",
       " 'tarts': 559,\n",
       " 'slates': 560,\n",
       " 'evidence': 561,\n",
       " 'trouble': 562,\n",
       " 'late': 563,\n",
       " 'fell': 564,\n",
       " 'somebody': 565,\n",
       " 'nice': 566,\n",
       " 'written': 567,\n",
       " 'leaves': 568,\n",
       " 'jumped': 569,\n",
       " 'roof': 570,\n",
       " 'inches': 571,\n",
       " 'along': 572,\n",
       " 'marked': 573,\n",
       " 'hold': 574,\n",
       " 'forgotten': 575,\n",
       " 'almost': 576,\n",
       " 'english': 577,\n",
       " \"'or\": 578,\n",
       " 'nonsense': 579,\n",
       " 'stop': 580,\n",
       " 'himself': 581,\n",
       " 'sir': 582,\n",
       " 'times': 583,\n",
       " 'repeat': 584,\n",
       " 'grin': 585,\n",
       " 'understand': 586,\n",
       " 'pardon': 587,\n",
       " \"'don't\": 588,\n",
       " 'trembling': 589,\n",
       " 'subject': 590,\n",
       " 'sit': 591,\n",
       " 'race': 592,\n",
       " 'politely': 593,\n",
       " 'melancholy': 594,\n",
       " 'liked': 595,\n",
       " 'exactly': 596,\n",
       " 'piece': 597,\n",
       " \"'you're\": 598,\n",
       " 'nobody': 599,\n",
       " 'executed': 600,\n",
       " 'broken': 601,\n",
       " 'chimney': 602,\n",
       " 'full': 603,\n",
       " 'loud': 604,\n",
       " 'sharp': 605,\n",
       " 'guinea': 606,\n",
       " 'pigs': 607,\n",
       " 'puppy': 608,\n",
       " 'arms': 609,\n",
       " \"'who\": 610,\n",
       " 'father': 611,\n",
       " 'youth': 612,\n",
       " 'sleep': 613,\n",
       " \"you've\": 614,\n",
       " 'sneezing': 615,\n",
       " 'between': 616,\n",
       " 'told': 617,\n",
       " 'ear': 618,\n",
       " 'cheshire': 619,\n",
       " 'everybody': 620,\n",
       " 'dreadfully': 621,\n",
       " 'writing': 622,\n",
       " 'sing': 623,\n",
       " 'exclaimed': 624,\n",
       " 'school': 625,\n",
       " 'soo': 626,\n",
       " 'e': 627,\n",
       " 'hole': 628,\n",
       " 'twice': 629,\n",
       " 'sleepy': 630,\n",
       " 'across': 631,\n",
       " 'curiosity': 632,\n",
       " 'passed': 633,\n",
       " 'home': 634,\n",
       " 'likely': 635,\n",
       " 'aloud': 636,\n",
       " 'walk': 637,\n",
       " 'new': 638,\n",
       " 'asking': 639,\n",
       " 'night': 640,\n",
       " 'sometimes': 641,\n",
       " 'walking': 642,\n",
       " 'ears': 643,\n",
       " 'sadly': 644,\n",
       " 'shut': 645,\n",
       " 'simple': 646,\n",
       " 'cut': 647,\n",
       " 'finger': 648,\n",
       " 'ten': 649,\n",
       " 'nervous': 650,\n",
       " 'altogether': 651,\n",
       " 'remembered': 652,\n",
       " \"'to\": 653,\n",
       " 'happens': 654,\n",
       " \"shan't\": 655,\n",
       " 'pair': 656,\n",
       " 'kid': 657,\n",
       " 'dropped': 658,\n",
       " 'usual': 659,\n",
       " 'morning': 660,\n",
       " 'seven': 661,\n",
       " 'wrong': 662,\n",
       " 'sounded': 663,\n",
       " 'strange': 664,\n",
       " 'seems': 665,\n",
       " 'stay': 666,\n",
       " 'sudden': 667,\n",
       " 'water': 668,\n",
       " 'case': 669,\n",
       " 'number': 670,\n",
       " 'swam': 671,\n",
       " 'nearer': 672,\n",
       " \"'would\": 673,\n",
       " 'speaking': 674,\n",
       " 'sentence': 675,\n",
       " 'shrill': 676,\n",
       " 'angry': 677,\n",
       " 'fetch': 678,\n",
       " 'crowded': 679,\n",
       " 'important': 680,\n",
       " 'means': 681,\n",
       " 'notice': 682,\n",
       " \"'one\": 683,\n",
       " 'chorus': 684,\n",
       " 'dare': 685,\n",
       " 'confusion': 686,\n",
       " 'call': 687,\n",
       " 'reply': 688,\n",
       " 'finish': 689,\n",
       " 'impatiently': 690,\n",
       " 'sighed': 691,\n",
       " 'temper': 692,\n",
       " 'young': 693,\n",
       " 'moved': 694,\n",
       " 'doing': 695,\n",
       " 'direction': 696,\n",
       " 'interesting': 697,\n",
       " 'become': 698,\n",
       " \"'when\": 699,\n",
       " 'write': 700,\n",
       " \"shouldn't\": 701,\n",
       " 'taking': 702,\n",
       " 'shriek': 703,\n",
       " 'drew': 704,\n",
       " 'sky': 705,\n",
       " 'instantly': 706,\n",
       " \"'i'll\": 707,\n",
       " 'surprise': 708,\n",
       " 'lizard': 709,\n",
       " 'height': 710,\n",
       " 'quietly': 711,\n",
       " 'hookah': 712,\n",
       " 'man': 713,\n",
       " 'stand': 714,\n",
       " 'often': 715,\n",
       " 'eggs': 716,\n",
       " 'meant': 717,\n",
       " 'waving': 718,\n",
       " \"'very\": 719,\n",
       " 'treacle': 720,\n",
       " 'faces': 721,\n",
       " 'procession': 722,\n",
       " 'pack': 723,\n",
       " 'knee': 724,\n",
       " 'whispered': 725,\n",
       " 'flamingo': 726,\n",
       " 'executioner': 727,\n",
       " 'evening': 728,\n",
       " 'pictures': 729,\n",
       " 'worth': 730,\n",
       " 'natural': 731,\n",
       " 'sides': 732,\n",
       " 'fear': 733,\n",
       " 'managed': 734,\n",
       " \"they'll\": 735,\n",
       " 'true': 736,\n",
       " 'fallen': 737,\n",
       " 'earth': 738,\n",
       " 'several': 739,\n",
       " 'sound': 740,\n",
       " 'girl': 741,\n",
       " 'miss': 742,\n",
       " 'mice': 743,\n",
       " 'bats': 744,\n",
       " 'passage': 745,\n",
       " 'corner': 746,\n",
       " 'except': 747,\n",
       " 'tiny': 748,\n",
       " 'alas': 749,\n",
       " 'second': 750,\n",
       " 'led': 751,\n",
       " 'shoulders': 752,\n",
       " \"'which\": 753,\n",
       " 'paper': 754,\n",
       " 'taught': 755,\n",
       " 'deeply': 756,\n",
       " 'drink': 757,\n",
       " 'ventured': 758,\n",
       " 'reach': 759,\n",
       " 'sharply': 760,\n",
       " 'severely': 761,\n",
       " 'fond': 762,\n",
       " 'person': 763,\n",
       " 'care': 764,\n",
       " 'nine': 765,\n",
       " 'until': 766,\n",
       " 'savage': 767,\n",
       " 'violently': 768,\n",
       " 'age': 769,\n",
       " 'mabel': 770,\n",
       " \"she's\": 771,\n",
       " 'puzzling': 772,\n",
       " 'twelve': 773,\n",
       " 'capital': 774,\n",
       " 'alone': 775,\n",
       " \"rabbit's\": 776,\n",
       " 'shrinking': 777,\n",
       " 'escape': 778,\n",
       " 'french': 779,\n",
       " 'fire': 780,\n",
       " 'paws': 781,\n",
       " \"'there\": 782,\n",
       " 'says': 783,\n",
       " 'pale': 784,\n",
       " 'shore': 785,\n",
       " \"you'll\": 786,\n",
       " 'animals': 787,\n",
       " 'duck': 788,\n",
       " 'tale': 789,\n",
       " 'uncomfortable': 790,\n",
       " 'argument': 791,\n",
       " 'wanted': 792,\n",
       " 'frowning': 793,\n",
       " 'solemnly': 794,\n",
       " 'prizes': 795,\n",
       " 'pointing': 796,\n",
       " 'confused': 797,\n",
       " \"'only\": 798,\n",
       " 'short': 799,\n",
       " 'bowed': 800,\n",
       " 'judge': 801,\n",
       " 'breath': 802,\n",
       " \"'please\": 803,\n",
       " \"'ah\": 804,\n",
       " \"'hold\": 805,\n",
       " 'tongue': 806,\n",
       " 'particular': 807,\n",
       " 'since': 808,\n",
       " 'swim': 809,\n",
       " 'vanished': 810,\n",
       " 'ann': 811,\n",
       " 'run': 812,\n",
       " 'chance': 813,\n",
       " 'answered': 814,\n",
       " 'outside': 815,\n",
       " \"'sure\": 816,\n",
       " 'yer': 817,\n",
       " 'honour': 818,\n",
       " 'sounds': 819,\n",
       " 'hearing': 820,\n",
       " \"bill's\": 821,\n",
       " 'slate': 822,\n",
       " 'master': 823,\n",
       " 'fellow': 824,\n",
       " 'dead': 825,\n",
       " 'doubt': 826,\n",
       " 'lay': 827,\n",
       " 'crowd': 828,\n",
       " 'held': 829,\n",
       " \"'is\": 830,\n",
       " 'plan': 831,\n",
       " 'difficulty': 832,\n",
       " 'stick': 833,\n",
       " 'grass': 834,\n",
       " 'perfectly': 835,\n",
       " 'none': 836,\n",
       " 'questions': 837,\n",
       " 'decidedly': 838,\n",
       " 'thoughtfully': 839,\n",
       " 'green': 840,\n",
       " 'screamed': 841,\n",
       " 'indignantly': 842,\n",
       " 'taken': 843,\n",
       " 'otherwise': 844,\n",
       " 'dish': 845,\n",
       " 'days': 846,\n",
       " 'kitchen': 847,\n",
       " 'jumping': 848,\n",
       " 'carried': 849,\n",
       " 'hours': 850,\n",
       " 'busily': 851,\n",
       " 'beat': 852,\n",
       " 'wow': 853,\n",
       " 'verse': 854,\n",
       " 'creature': 855,\n",
       " 'grunted': 856,\n",
       " 'less': 857,\n",
       " \"'call\": 858,\n",
       " \"'i'd\": 859,\n",
       " 'fast': 860,\n",
       " 'shoulder': 861,\n",
       " 'twinkling': 862,\n",
       " 'sigh': 863,\n",
       " 'bottom': 864,\n",
       " 'begins': 865,\n",
       " 'm': 866,\n",
       " 'rose': 867,\n",
       " 'rule': 868,\n",
       " \"'she\": 869,\n",
       " 'arches': 870,\n",
       " 'players': 871,\n",
       " 'hers': 872,\n",
       " 'quadrille': 873,\n",
       " 'sobs': 874,\n",
       " 'porpoise': 875,\n",
       " 'mouths': 876,\n",
       " 'beau': 877,\n",
       " 'ootiful': 878,\n",
       " 'jurors': 879,\n",
       " 'verdict': 880,\n",
       " 'officers': 881,\n",
       " 'suppressed': 882,\n",
       " 'jurymen': 883,\n",
       " \"'nothing\": 884,\n",
       " 'verses': 885,\n",
       " 'wonderland': 886,\n",
       " 'bank': 887,\n",
       " 'peeped': 888,\n",
       " 'reading': 889,\n",
       " 'considering': 890,\n",
       " 'stupid': 891,\n",
       " 'dark': 892,\n",
       " 'filled': 893,\n",
       " 'past': 894,\n",
       " 'stairs': 895,\n",
       " 'miles': 896,\n",
       " 'somewhere': 897,\n",
       " 'knowledge': 898,\n",
       " 'grand': 899,\n",
       " 'funny': 900,\n",
       " 'listening': 901,\n",
       " \"she'll\": 902,\n",
       " 'hope': 903,\n",
       " 'catch': 904,\n",
       " 'bat': 905,\n",
       " 'hurt': 906,\n",
       " 'lost': 907,\n",
       " 'whiskers': 908,\n",
       " 'longer': 909,\n",
       " 'hanging': 910,\n",
       " 'delight': 911,\n",
       " 'telescope': 912,\n",
       " 'impossible': 913,\n",
       " 'hoping': 914,\n",
       " 'rules': 915,\n",
       " \"'drink\": 916,\n",
       " 'red': 917,\n",
       " 'knife': 918,\n",
       " 'certain': 919,\n",
       " 'later': 920,\n",
       " 'finding': 921,\n",
       " 'further': 922,\n",
       " 'candle': 923,\n",
       " 'decided': 924,\n",
       " 'possibly': 925,\n",
       " 'legs': 926,\n",
       " 'cake': 927,\n",
       " 'smaller': 928,\n",
       " 'holding': 929,\n",
       " 'remained': 930,\n",
       " 'expecting': 931,\n",
       " 'dull': 932,\n",
       " 'opening': 933,\n",
       " 'dears': 934,\n",
       " 'boots': 935,\n",
       " 'directions': 936,\n",
       " 'love': 937,\n",
       " 'cry': 938,\n",
       " 'pattering': 939,\n",
       " 'muttering': 940,\n",
       " 'timid': 941,\n",
       " 'yesterday': 942,\n",
       " 'sorts': 943,\n",
       " 'besides': 944,\n",
       " \"let's\": 945,\n",
       " 'doth': 946,\n",
       " 'crossed': 947,\n",
       " 'hoarse': 948,\n",
       " 'spread': 949,\n",
       " 'gently': 950,\n",
       " 'putting': 951,\n",
       " 'guess': 952,\n",
       " 'cause': 953,\n",
       " 'worse': 954,\n",
       " 'slipped': 955,\n",
       " 'general': 956,\n",
       " 'digging': 957,\n",
       " \"'perhaps\": 958,\n",
       " 'notion': 959,\n",
       " 'lesson': 960,\n",
       " 'show': 961,\n",
       " 'washing': 962,\n",
       " 'nurse': 963,\n",
       " 'dogs': 964,\n",
       " 'throw': 965,\n",
       " 'passion': 966,\n",
       " \"'let\": 967,\n",
       " 'eaglet': 968,\n",
       " 'caucus': 969,\n",
       " 'fur': 970,\n",
       " 'cross': 971,\n",
       " 'sulky': 972,\n",
       " \"'did\": 973,\n",
       " 'frog': 974,\n",
       " 'crown': 975,\n",
       " 'move': 976,\n",
       " 'pressed': 977,\n",
       " 'voices': 978,\n",
       " 'handed': 979,\n",
       " 'gravely': 980,\n",
       " 'thimble': 981,\n",
       " 'speech': 982,\n",
       " 'cheered': 983,\n",
       " 'grave': 984,\n",
       " 'simply': 985,\n",
       " 'solemn': 986,\n",
       " 'noise': 987,\n",
       " 'choked': 988,\n",
       " 'whisper': 989,\n",
       " 'sad': 990,\n",
       " 'sighing': 991,\n",
       " 'met': 992,\n",
       " 'attending': 993,\n",
       " 'pleaded': 994,\n",
       " 'easily': 995,\n",
       " 'joined': 996,\n",
       " 'pity': 997,\n",
       " 'crab': 998,\n",
       " 'venture': 999,\n",
       " 'carefully': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901948f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create input sequences\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2464fdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[315, 490],\n",
       " [315, 490, 11],\n",
       " [315, 490, 11, 886],\n",
       " [315, 490, 11, 886, 69],\n",
       " [315, 490, 11, 886, 69, 1585],\n",
       " [315, 490, 11, 886, 69, 1585, 1586],\n",
       " [315, 490, 11, 886, 69, 1585, 1586, 1587],\n",
       " [316, 14],\n",
       " [316, 14, 36],\n",
       " [316, 14, 36, 1],\n",
       " [316, 14, 36, 1, 99],\n",
       " [316, 14, 36, 1, 99, 628],\n",
       " [10, 12],\n",
       " [10, 12, 268],\n",
       " [10, 12, 268, 4],\n",
       " [10, 12, 268, 4, 105],\n",
       " [10, 12, 268, 4, 105, 26],\n",
       " [10, 12, 268, 4, 105, 26, 491],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7, 368],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7, 368, 69],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7, 368, 69, 17],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7, 368, 69, 17, 441],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7, 368, 69, 17, 441, 19],\n",
       " [10, 12, 268, 4, 105, 26, 491, 7, 368, 69, 17, 441, 19, 1],\n",
       " [887, 3],\n",
       " [887, 3, 7],\n",
       " [887, 3, 7, 369],\n",
       " [887, 3, 7, 369, 145],\n",
       " [887, 3, 7, 369, 145, 4],\n",
       " [887, 3, 7, 369, 145, 4, 57],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58, 629],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58, 629, 6],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58, 629, 6, 22],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58, 629, 6, 22, 888],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58, 629, 6, 22, 888, 62],\n",
       " [887, 3, 7, 369, 145, 4, 57, 137, 58, 629, 6, 22, 888, 62, 1],\n",
       " [344, 17],\n",
       " [344, 17, 441],\n",
       " [344, 17, 441, 12],\n",
       " [344, 17, 441, 12, 889],\n",
       " [344, 17, 441, 12, 889, 28],\n",
       " [344, 17, 441, 12, 889, 28, 8],\n",
       " [344, 17, 441, 12, 889, 28, 8, 22],\n",
       " [344, 17, 441, 12, 889, 28, 8, 22, 51],\n",
       " [344, 17, 441, 12, 889, 28, 8, 22, 51, 729],\n",
       " [344, 17, 441, 12, 889, 28, 8, 22, 51, 729, 58],\n",
       " [344, 17, 441, 12, 889, 28, 8, 22, 51, 729, 58, 1588],\n",
       " [344, 17, 441, 12, 889, 28, 8, 22, 51, 729, 58, 1588, 11],\n",
       " [8, 73],\n",
       " [8, 73, 37],\n",
       " [8, 73, 37, 35],\n",
       " [8, 73, 37, 35, 1],\n",
       " [8, 73, 37, 35, 1, 221],\n",
       " [8, 73, 37, 35, 1, 221, 7],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344, 2],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344, 2, 55],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344, 2, 55, 10],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344, 2, 55, 10, 1589],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344, 2, 55, 10, 1589, 729],\n",
       " [8, 73, 37, 35, 1, 221, 7, 5, 344, 2, 55, 10, 1589, 729, 58],\n",
       " [370, 2],\n",
       " [25, 6],\n",
       " [25, 6, 12],\n",
       " [25, 6, 12, 890],\n",
       " [25, 6, 12, 890, 11],\n",
       " [25, 6, 12, 890, 11, 17],\n",
       " [25, 6, 12, 890, 11, 17, 371],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16, 112],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16, 112, 16],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16, 112, 16, 6],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16, 112, 16, 6, 52],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16, 112, 16, 6, 52, 24],\n",
       " [25, 6, 12, 890, 11, 17, 371, 345, 16, 112, 16, 6, 52, 24, 1],\n",
       " [492, 153],\n",
       " [492, 153, 146],\n",
       " [492, 153, 146, 17],\n",
       " [492, 153, 146, 17, 442],\n",
       " [492, 153, 146, 17, 442, 26],\n",
       " [492, 153, 146, 17, 442, 26, 630],\n",
       " [492, 153, 146, 17, 442, 26, 630, 3],\n",
       " [492, 153, 146, 17, 442, 26, 630, 3, 891],\n",
       " [492, 153, 146, 17, 442, 26, 630, 3, 891, 346],\n",
       " [492, 153, 146, 17, 442, 26, 630, 3, 891, 346, 1],\n",
       " [492, 153, 146, 17, 442, 26, 630, 3, 891, 346, 1, 1141],\n",
       " [7, 443],\n",
       " [7, 443, 5],\n",
       " [7, 443, 5, 1590],\n",
       " [7, 443, 5, 1590, 1591],\n",
       " [7, 443, 5, 1590, 1591, 50],\n",
       " [7, 443, 5, 1590, 1591, 50, 23],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730, 1],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730, 1, 562],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730, 1, 562, 7],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730, 1, 562, 7, 191],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730, 1, 562, 7, 191, 38],\n",
       " [7, 443, 5, 1590, 1591, 50, 23, 730, 1, 562, 7, 191, 38, 3],\n",
       " [1142, 1],\n",
       " [1142, 1, 1592],\n",
       " [1142, 1, 1592, 56],\n",
       " [1142, 1, 1592, 56, 290],\n",
       " [1142, 1, 1592, 56, 290, 5],\n",
       " [1142, 1, 1592, 56, 290, 5, 147],\n",
       " [1142, 1, 1592, 56, 290, 5, 147, 99],\n",
       " [1142, 1, 1592, 56, 290, 5, 147, 99, 20],\n",
       " [1142, 1, 1592, 56, 290, 5, 147, 99, 20, 1593],\n",
       " [1142, 1, 1592, 56, 290, 5, 147, 99, 20, 1593, 154],\n",
       " [1142, 1, 1592, 56, 290, 5, 147, 99, 20, 1593, 154, 240],\n",
       " [291, 69],\n",
       " [291, 69, 17],\n",
       " [59, 12],\n",
       " [59, 12, 145],\n",
       " [59, 12, 145, 25],\n",
       " [59, 12, 145, 25, 26],\n",
       " [59, 12, 145, 25, 26, 1143],\n",
       " [59, 12, 145, 25, 26, 1143, 11],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15, 1144],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15, 1144, 67],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15, 1144, 67, 10],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15, 1144, 67, 10, 83],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15, 1144, 67, 10, 83, 8],\n",
       " [59, 12, 145, 25, 26, 1143, 11, 15, 1144, 67, 10, 83, 8, 25],\n",
       " [26, 85],\n",
       " [26, 85, 33],\n",
       " [26, 85, 33, 7],\n",
       " [26, 85, 33, 7, 1],\n",
       " [26, 85, 33, 7, 1, 74],\n",
       " [26, 85, 33, 7, 1, 74, 4],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1, 99],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1, 99, 86],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1, 99, 86, 4],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1, 99, 86, 4, 270],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1, 99, 86, 4, 270, 182],\n",
       " [26, 85, 33, 7, 1, 74, 4, 269, 1, 99, 86, 4, 270, 182, 158],\n",
       " [192, 158],\n",
       " [192, 158, 14],\n",
       " [192, 158, 14, 183],\n",
       " [192, 158, 14, 183, 23],\n",
       " [192, 158, 14, 183, 23, 563],\n",
       " [192, 158, 14, 183, 23, 563, 2],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56, 6],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56, 6, 55],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56, 6, 55, 8],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56, 6, 55, 8, 113],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56, 6, 55, 8, 113, 1145],\n",
       " [192, 158, 14, 183, 23, 563, 2, 56, 6, 55, 8, 113, 1145, 8],\n",
       " [1146, 4],\n",
       " [1146, 4, 17],\n",
       " [1146, 4, 17, 15],\n",
       " [1146, 4, 17, 15, 6],\n",
       " [1146, 4, 17, 15, 6, 271],\n",
       " [1146, 4, 17, 15, 6, 271, 4],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594, 18],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594, 18, 29],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594, 18, 29, 28],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594, 18, 29, 28, 18],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594, 18, 29, 28, 18, 1],\n",
       " [1146, 4, 17, 15, 6, 271, 4, 53, 1594, 18, 29, 28, 18, 1, 60],\n",
       " [8, 21],\n",
       " [8, 21, 161],\n",
       " [8, 21, 161, 78],\n",
       " [8, 21, 161, 78, 731],\n",
       " [8, 21, 161, 78, 731, 28],\n",
       " [8, 21, 161, 78, 731, 28, 56],\n",
       " [8, 21, 161, 78, 731, 28, 56, 1],\n",
       " [8, 21, 161, 78, 731, 28, 56, 1, 99],\n",
       " [8, 21, 161, 78, 731, 28, 56, 1, 99, 1595],\n",
       " [8, 21, 161, 78, 731, 28, 56, 1, 99, 1595, 180],\n",
       " [8, 21, 161, 78, 731, 28, 56, 1, 99, 1595, 180, 5],\n",
       " [8, 21, 161, 78, 731, 28, 56, 1, 99, 1595, 180, 5, 444],\n",
       " [33, 7],\n",
       " [33, 7, 71],\n",
       " [33, 7, 71, 1147],\n",
       " [33, 7, 71, 1147, 493],\n",
       " [33, 7, 71, 1147, 493, 3],\n",
       " [33, 7, 71, 1147, 493, 3, 101],\n",
       " [33, 7, 71, 1147, 493, 3, 101, 18],\n",
       " [33, 7, 71, 1147, 493, 3, 101, 18, 8],\n",
       " [33, 7, 71, 1147, 493, 3, 101, 18, 8, 3],\n",
       " [33, 7, 71, 1147, 493, 3, 101, 18, 8, 3, 49],\n",
       " [33, 7, 71, 1147, 493, 3, 101, 18, 8, 3, 49, 347],\n",
       " [33, 7, 71, 1147, 493, 3, 101, 18, 8, 3, 49, 347, 19],\n",
       " [10, 1148],\n",
       " [10, 1148, 4],\n",
       " [10, 1148, 4, 17],\n",
       " [10, 1148, 4, 17, 210],\n",
       " [10, 1148, 4, 17, 210, 24],\n",
       " [10, 1148, 4, 17, 210, 24, 8],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596, 631],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596, 631, 17],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596, 631, 17, 345],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596, 631, 17, 345, 15],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596, 631, 17, 345, 15, 6],\n",
       " [10, 1148, 4, 17, 210, 24, 8, 1596, 631, 17, 345, 15, 6, 22],\n",
       " [102, 123],\n",
       " [102, 123, 252],\n",
       " [102, 123, 252, 5],\n",
       " [102, 123, 252, 5, 99],\n",
       " [102, 123, 252, 5, 99, 20],\n",
       " [102, 123, 252, 5, 99, 20, 407],\n",
       " [102, 123, 252, 5, 99, 20, 407, 5],\n",
       " [102, 123, 252, 5, 99, 20, 407, 5, 1147],\n",
       " [102, 123, 252, 5, 99, 20, 407, 5, 1147, 493],\n",
       " [102, 123, 252, 5, 99, 20, 407, 5, 1147, 493, 58],\n",
       " [102, 123, 252, 5, 99, 20, 407, 5, 1147, 493, 58, 5],\n",
       " [102, 123, 252, 5, 99, 20, 407, 5, 1147, 493, 58, 5, 444],\n",
       " [4, 203],\n",
       " [4, 203, 33],\n",
       " [4, 203, 33, 7],\n",
       " [4, 203, 33, 7, 8],\n",
       " [4, 203, 33, 7, 8, 3],\n",
       " [4, 203, 33, 7, 8, 3, 1597],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20, 632],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20, 632, 6],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20, 632, 6, 240],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20, 632, 6, 240, 631],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20, 632, 6, 240, 631, 1],\n",
       " [4, 203, 33, 7, 8, 3, 1597, 20, 632, 6, 240, 631, 1, 1598],\n",
       " [109, 8],\n",
       " [109, 8, 3],\n",
       " [109, 8, 3, 1599],\n",
       " [109, 8, 3, 1599, 12],\n",
       " [109, 8, 3, 1599, 12, 91],\n",
       " [109, 8, 3, 1599, 12, 91, 11],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4, 63],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4, 63, 8],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4, 63, 8, 1600],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4, 63, 8, 1600, 36],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4, 63, 8, 1600, 36, 5],\n",
       " [109, 8, 3, 1599, 12, 91, 11, 60, 4, 63, 8, 1600, 36, 5, 133],\n",
       " [99, 628],\n",
       " [99, 628, 241],\n",
       " [99, 628, 241, 1],\n",
       " [99, 628, 241, 1, 1149],\n",
       " [11, 193],\n",
       " [11, 193, 155],\n",
       " [11, 193, 155, 36],\n",
       " [11, 193, 155, 36, 46],\n",
       " [11, 193, 155, 36, 46, 10],\n",
       " [11, 193, 155, 36, 46, 10, 109],\n",
       " [11, 193, 155, 36, 46, 10, 109, 8],\n",
       " [11, 193, 155, 36, 46, 10, 109, 8, 102],\n",
       " [11, 193, 155, 36, 46, 10, 109, 8, 102, 137],\n",
       " [11, 193, 155, 36, 46, 10, 109, 8, 102, 137, 890],\n",
       " [11, 193, 155, 36, 46, 10, 109, 8, 102, 137, 890, 84],\n",
       " [11, 1],\n",
       " [11, 1, 494],\n",
       " [11, 1, 494, 6],\n",
       " [11, 1, 494, 6, 12],\n",
       " [11, 1, 494, 6, 12, 4],\n",
       " [11, 1, 494, 6, 12, 4, 105],\n",
       " [11, 1, 494, 6, 12, 4, 105, 33],\n",
       " [11, 1, 494, 6, 12, 4, 105, 33, 47],\n",
       " [1, 99],\n",
       " [1, 99, 628],\n",
       " [1, 99, 628, 46],\n",
       " [1, 99, 628, 46, 1150],\n",
       " [1, 99, 628, 46, 1150, 19],\n",
       " [1, 99, 628, 46, 1150, 19, 44],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5, 1601],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5, 1601, 24],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5, 1601, 24, 88],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5, 1601, 24, 88, 74],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5, 1601, 24, 88, 74, 3],\n",
       " [1, 99, 628, 46, 1150, 19, 44, 5, 1601, 24, 88, 74, 3, 49],\n",
       " [1151, 290],\n",
       " [1151, 290, 36],\n",
       " [1151, 290, 36, 25],\n",
       " [1151, 290, 36, 25, 290],\n",
       " [1151, 290, 36, 25, 290, 15],\n",
       " [1151, 290, 36, 25, 290, 15, 10],\n",
       " [1151, 290, 36, 25, 290, 15, 10, 22],\n",
       " [1151, 290, 36, 25, 290, 15, 10, 22, 27],\n",
       " [1151, 290, 36, 25, 290, 15, 10, 22, 27, 5],\n",
       " [1151, 290, 36, 25, 290, 15, 10, 22, 27, 5, 155],\n",
       " [1151, 290, 36, 25, 290, 15, 10, 22, 27, 5, 155, 4],\n",
       " [1151, 290, 36, 25, 290, 15, 10, 22, 27, 5, 155, 4, 83],\n",
       " [41, 1602],\n",
       " [41, 1602, 48],\n",
       " [41, 1602, 48, 123],\n",
       " [41, 1602, 48, 123, 6],\n",
       " [41, 1602, 48, 123, 6, 148],\n",
       " [41, 1602, 48, 123, 6, 148, 48],\n",
       " [41, 1602, 48, 123, 6, 148, 48, 1152],\n",
       " [41, 1602, 48, 123, 6, 148, 48, 1152, 36],\n",
       " [41, 1602, 48, 123, 6, 148, 48, 1152, 36, 5],\n",
       " [41, 1602, 48, 123, 6, 148, 48, 1152, 36, 5, 26],\n",
       " [41, 1602, 48, 123, 6, 148, 48, 1152, 36, 5, 26, 495],\n",
       " [407, 1],\n",
       " [407, 1, 112],\n",
       " [407, 1, 112, 12],\n",
       " [407, 1, 112, 12, 26],\n",
       " [407, 1, 112, 12, 26, 495],\n",
       " [407, 1, 112, 12, 26, 495, 58],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6, 564],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6, 564, 26],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6, 564, 26, 445],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6, 564, 26, 445, 24],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6, 564, 26, 445, 24, 6],\n",
       " [407, 1, 112, 12, 26, 495, 58, 6, 564, 26, 445, 24, 6, 22],\n",
       " [1153, 7],\n",
       " [1153, 7, 60],\n",
       " [1153, 7, 60, 16],\n",
       " [1153, 7, 60, 16, 6],\n",
       " [1153, 7, 60, 16, 6, 46],\n",
       " [1153, 7, 60, 16, 6, 46, 36],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41, 17],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41, 17, 3],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41, 17, 3, 4],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41, 17, 3, 4, 222],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41, 17, 3, 4, 222, 37],\n",
       " [1153, 7, 60, 16, 6, 46, 36, 4, 159, 41, 17, 3, 4, 222, 37, 12],\n",
       " [162, 4],\n",
       " [162, 4, 446],\n",
       " [162, 4, 446, 149],\n",
       " [162, 4, 446, 149, 89],\n",
       " [162, 4, 446, 149, 89, 6],\n",
       " [162, 4, 446, 149, 89, 6, 211],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4, 159],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4, 159, 36],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4, 159, 36, 3],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4, 159, 36, 3, 163],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4, 159, 36, 3, 163, 33],\n",
       " [162, 4, 446, 149, 89, 6, 211, 4, 159, 36, 3, 163, 33, 37],\n",
       " [6, 12],\n",
       " [6, 12, 408],\n",
       " [6, 12, 408, 4],\n",
       " [6, 12, 408, 4, 28],\n",
       " [6, 12, 408, 4, 28, 8],\n",
       " [6, 12, 408, 4, 28, 8, 12],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169, 892],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169, 892, 4],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169, 892, 4, 63],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169, 892, 4, 63, 212],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169, 892, 4, 63, 212, 49],\n",
       " [6, 12, 408, 4, 28, 8, 12, 169, 892, 4, 63, 212, 49, 6],\n",
       " [101, 18],\n",
       " [101, 18, 1],\n",
       " [101, 18, 1, 732],\n",
       " [101, 18, 1, 732, 7],\n",
       " [101, 18, 1, 732, 7, 1],\n",
       " [101, 18, 1, 732, 7, 1, 112],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3, 447],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3, 447, 15],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3, 447, 15, 32],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3, 447, 15, 32, 45],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3, 447, 15, 32, 45, 893],\n",
       " [101, 18, 1, 732, 7, 1, 112, 3, 447, 15, 32, 45, 893, 20],\n",
       " [1154, 3],\n",
       " [1154, 3, 344],\n",
       " [1154, 3, 344, 1155],\n",
       " [1154, 3, 344, 1155, 95],\n",
       " [1154, 3, 344, 1155, 95, 3],\n",
       " [1154, 3, 344, 1155, 95, 3, 59],\n",
       " [1154, 3, 344, 1155, 95, 3, 59, 6],\n",
       " [1154, 3, 344, 1155, 95, 3, 59, 6, 272],\n",
       " [1154, 3, 344, 1155, 95, 3, 59, 6, 272, 1603],\n",
       " [1154, 3, 344, 1155, 95, 3, 59, 6, 272, 1603, 3],\n",
       " [1154, 3, 344, 1155, 95, 3, 59, 6, 272, 1603, 3, 729],\n",
       " [1604, 170],\n",
       " [1604, 170, 1605],\n",
       " [1604, 170, 1605, 6],\n",
       " [1604, 170, 1605, 6, 180],\n",
       " [1604, 170, 1605, 6, 180, 36],\n",
       " [1604, 170, 1605, 6, 180, 36, 5],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156, 128],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156, 128, 39],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156, 128, 39, 7],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156, 128, 39, 7, 1],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156, 128, 39, 7, 1, 1155],\n",
       " [1604, 170, 1605, 6, 180, 36, 5, 1156, 128, 39, 7, 1, 1155, 16],\n",
       " [6, 633],\n",
       " [6, 633, 8],\n",
       " [6, 633, 8, 12],\n",
       " [6, 633, 8, 12, 1606],\n",
       " [6, 633, 8, 12, 1606, 1607],\n",
       " [6, 633, 8, 12, 1606, 1607, 1608],\n",
       " [6, 633, 8, 12, 1606, 1607, 1608, 28],\n",
       " [6, 633, 8, 12, 1606, 1607, 1608, 28, 4],\n",
       " [6, 633, 8, 12, 1606, 1607, 1608, 28, 4, 17],\n",
       " [6, 633, 8, 12, 1606, 1607, 1608, 28, 4, 17, 118],\n",
       " [1609, 8],\n",
       " [1609, 8, 12],\n",
       " [1609, 8, 12, 1610],\n",
       " [1609, 8, 12, 1610, 6],\n",
       " [1609, 8, 12, 1610, 6, 67],\n",
       " [1609, 8, 12, 1610, 6, 67, 27],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44, 4],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44, 4, 1611],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44, 4, 1611, 1],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44, 4, 1611, 1, 1156],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44, 4, 1611, 1, 1156, 24],\n",
       " [1609, 8, 12, 1610, 6, 67, 27, 44, 4, 1611, 1, 1156, 24, 733],\n",
       " [7, 1612],\n",
       " [7, 1612, 565],\n",
       " [7, 1612, 565, 25],\n",
       " [7, 1612, 565, 25, 734],\n",
       " [7, 1612, 565, 25, 734, 4],\n",
       " [7, 1612, 565, 25, 734, 4, 140],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8, 62],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8, 62, 39],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8, 62, 39, 7],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8, 62, 39, 7, 1],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8, 62, 39, 7, 1, 1154],\n",
       " [7, 1612, 565, 25, 734, 4, 140, 8, 62, 39, 7, 1, 1154, 16],\n",
       " [6, 564],\n",
       " [6, 564, 894],\n",
       " [6, 564, 894, 8],\n",
       " [184, 2],\n",
       " [184, 2, 55],\n",
       " [184, 2, 55, 10],\n",
       " [184, 2, 55, 10, 4],\n",
       " [184, 2, 55, 10, 4, 48],\n",
       " [184, 2, 55, 10, 4, 48, 1157],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110, 5],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110, 5, 496],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110, 5, 496, 16],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110, 5, 496, 16, 29],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110, 5, 496, 16, 29, 14],\n",
       " [184, 2, 55, 10, 4, 48, 1157, 110, 5, 496, 16, 29, 14, 183],\n",
       " [83, 145],\n",
       " [83, 145, 7],\n",
       " [83, 145, 7, 1158],\n",
       " [83, 145, 7, 1158, 36],\n",
       " [83, 145, 7, 1158, 36, 895],\n",
       " [83, 145, 7, 1158, 36, 895, 84],\n",
       " [83, 145, 7, 1158, 36, 895, 84, 1613],\n",
       " [83, 145, 7, 1158, 36, 895, 84, 1613, 735],\n",
       " [83, 145, 7, 1158, 36, 895, 84, 1613, 735, 21],\n",
       " [83, 145, 7, 1158, 36, 895, 84, 1613, 735, 21, 83],\n",
       " [83, 145, 7, 1158, 36, 895, 84, 1613, 735, 21, 83, 64],\n",
       " [83, 145, 7, 1158, 36, 895, 84, 1613, 735, 21, 83, 64, 18],\n",
       " [634, 223],\n",
       " [634, 223, 14],\n",
       " [634, 223, 14, 317],\n",
       " [634, 223, 14, 317, 86],\n",
       " [634, 223, 14, 317, 86, 212],\n",
       " [634, 223, 14, 317, 86, 212, 41],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213, 54],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213, 54, 14],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213, 54, 14, 564],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213, 54, 14, 564, 65],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213, 54, 14, 564, 65, 1],\n",
       " [634, 223, 14, 317, 86, 212, 41, 8, 213, 54, 14, 564, 65, 1, 448],\n",
       " [7, 1],\n",
       " [7, 1, 224],\n",
       " [7, 1, 224, 2],\n",
       " [7, 1, 224, 2, 103],\n",
       " [7, 1, 224, 2, 103, 12],\n",
       " [7, 1, 224, 2, 103, 12, 26],\n",
       " [7, 1, 224, 2, 103, 12, 26, 635],\n",
       " [7, 1, 224, 2, 103, 12, 26, 635, 736],\n",
       " [36, 36],\n",
       " [36, 36, 36],\n",
       " [36, 36, 36, 50],\n",
       " [36, 36, 36, 50, 1],\n",
       " [36, 36, 36, 50, 1, 496],\n",
       " [36, 36, 36, 50, 1, 496, 102],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141, 4],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141, 4, 75],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141, 4, 75, 231],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141, 4, 75, 231, 31],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141, 4, 75, 231, 31, 222],\n",
       " [36, 36, 36, 50, 1, 496, 102, 141, 4, 75, 231, 31, 222, 84],\n",
       " [318, 896],\n",
       " [318, 896, 204],\n",
       " [318, 896, 204, 737],\n",
       " [318, 896, 204, 737, 69],\n",
       " [318, 896, 204, 737, 69, 29],\n",
       " [318, 896, 204, 737, 69, 29, 60],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6, 9],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6, 9, 636],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6, 9, 636, 31],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6, 9, 636, 31, 106],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6, 9, 636, 31, 106, 23],\n",
       " [318, 896, 204, 737, 69, 29, 60, 2, 6, 9, 636, 31, 106, 23, 191],\n",
       " [897, 253],\n",
       " [897, 253, 1],\n",
       " [897, 253, 1, 1614],\n",
       " [897, 253, 1, 1614, 7],\n",
       " [897, 253, 1, 1614, 7, 1],\n",
       " [897, 253, 1, 1614, 7, 1, 738],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273, 64],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273, 64, 63],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273, 64, 63, 15],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273, 64, 63, 15, 50],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273, 64, 63, 15, 50, 23],\n",
       " [897, 253, 1, 1614, 7, 1, 738, 273, 64, 63, 15, 50, 23, 449],\n",
       " [1159, 896],\n",
       " [1159, 896, 36],\n",
       " [1159, 896, 36, 14],\n",
       " [1159, 896, 36, 14, 83],\n",
       " [1159, 896, 36, 14, 83, 2],\n",
       " [1159, 896, 36, 14, 83, 2, 24],\n",
       " [1159, 896, 36, 14, 83, 2, 24, 13],\n",
       " [1159, 896, 36, 14, 83, 2, 24, 13, 63],\n",
       " [1159, 896, 36, 14, 83, 2, 24, 13, 63, 10],\n",
       " [1159, 896, 36, 14, 83, 2, 24, 13, 63, 10, 22],\n",
       " [1159, 896, 36, 14, 83, 2, 24, 13, 63, 10, 22, 1160],\n",
       " [1159, 896, 36, 14, 83, 2, 24, 13, 63, 10, 22, 1160, 739],\n",
       " [142, 7],\n",
       " [142, 7, 29],\n",
       " [142, 7, 29, 205],\n",
       " [142, 7, 29, 205, 11],\n",
       " [142, 7, 29, 205, 11, 17],\n",
       " [142, 7, 29, 205, 11, 17, 372],\n",
       " [142, 7, 29, 205, 11, 17, 372, 11],\n",
       " [142, 7, 29, 205, 11, 17, 372, 11, 1],\n",
       " [142, 7, 29, 205, 11, 17, 372, 11, 1, 1615],\n",
       " [142, 7, 29, 205, 11, 17, 372, 11, 1, 1615, 3],\n",
       " [142, 7, 29, 205, 11, 17, 372, 11, 1, 1615, 3, 348],\n",
       " [142, 7, 29, 205, 11, 17, 372, 11, 1, 1615, 3, 348, 29],\n",
       " [12, 27],\n",
       " [12, 27, 5],\n",
       " [12, 27, 5, 26],\n",
       " [12, 27, 5, 26, 164],\n",
       " [12, 27, 5, 26, 164, 450],\n",
       " [12, 27, 5, 26, 164, 450, 24],\n",
       " [12, 27, 5, 26, 164, 450, 24, 1161],\n",
       " [12, 27, 5, 26, 164, 450, 24, 1161, 65],\n",
       " [12, 27, 5, 26, 164, 450, 24, 1161, 65, 17],\n",
       " [12, 27, 5, 26, 164, 450, 24, 1161, 65, 17, 898],\n",
       " [12, 27, 5, 26, 164, 450, 24, 1161, 65, 17, 898, 16],\n",
       " [12, 27, 5, 26, 164, 450, 24, 1161, 65, 17, 898, 16, 59],\n",
       " [12, 51],\n",
       " [12, 51, 39],\n",
       " [12, 51, 39, 4],\n",
       " [12, 51, 39, 4, 497],\n",
       " [12, 51, 39, 4, 497, 4],\n",
       " [12, 51, 39, 4, 497, 4, 17],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12, 164],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12, 164, 1616],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12, 164, 1616, 4],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12, 164, 1616, 4, 86],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12, 164, 1616, 4, 86, 8],\n",
       " [12, 51, 39, 4, 497, 4, 17, 292, 8, 12, 164, 1616, 4, 86, 8, 113],\n",
       " [2, 1617],\n",
       " [2, 1617, 225],\n",
       " [2, 1617, 225, 41],\n",
       " [2, 1617, 225, 41, 1],\n",
       " [2, 1617, 225, 41, 1, 143],\n",
       " [2, 1617, 225, 41, 1, 143, 451],\n",
       " [2, 1617, 225, 41, 1, 143, 451, 28],\n",
       " [2, 1617, 225, 41, 1, 143, 451, 28, 49],\n",
       " [2, 1617, 225, 41, 1, 143, 451, 28, 49, 14],\n",
       " [2, 1617, 225, 41, 1, 143, 451, 28, 49, 14, 222],\n",
       " [2, 1617, 225, 41, 1, 143, 451, 28, 49, 14, 222, 37],\n",
       " [2, 1617, 225, 41, 1, 143, 451, 28, 49, 14, 222, 37, 1162],\n",
       " [58, 1163],\n",
       " [58, 1163, 204],\n",
       " [58, 1163, 204, 104],\n",
       " [58, 1163, 204, 104, 4],\n",
       " [58, 1163, 204, 104, 4, 2],\n",
       " [58, 1163, 204, 104, 4, 2, 10],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22, 51],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22, 51, 254],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22, 51, 254, 37],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22, 51, 254, 37, 1162],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22, 51, 254, 37, 1162, 12],\n",
       " [58, 1163, 204, 104, 4, 2, 10, 22, 51, 254, 37, 1162, 12, 58],\n",
       " [1163, 407],\n",
       " [1163, 407, 28],\n",
       " [1163, 407, 28, 55],\n",
       " [1163, 407, 28, 55, 32],\n",
       " [1163, 407, 28, 55, 32, 45],\n",
       " [1163, 407, 28, 55, 32, 45, 566],\n",
       " [1163, 407, 28, 55, 32, 45, 566, 899],\n",
       " [1163, 407, 28, 55, 32, 45, 566, 899, 195],\n",
       " [1163, 407, 28, 55, 32, 45, 566, 899, 195, 4],\n",
       " [1163, 407, 28, 55, 32, 45, 566, 899, 195, 4, 86],\n",
       " [1164, 6],\n",
       " [1164, 6, 70],\n",
       " [1164, 6, 70, 47],\n",
       " [1164, 6, 70, 47, 31],\n",
       " [1164, 6, 70, 47, 31, 222],\n",
       " [1164, 6, 70, 47, 31, 222, 54],\n",
       " [1164, 6, 70, 47, 31, 222, 54, 14],\n",
       " [1164, 6, 70, 47, 31, 222, 54, 14, 183],\n",
       " [1164, 6, 70, 47, 31, 222, 54, 14, 183, 496],\n",
       " [1164, 6, 70, 47, 31, 222, 54, 14, 183, 496, 143],\n",
       " [1164, 6, 70, 47, 31, 222, 54, 14, 183, 496, 143, 274],\n",
       " [1164, 6, 70, 47, 31, 222, 54, 14, 183, 496, 143, 274, 1],\n",
       " [738, 84],\n",
       " [738, 84, 900],\n",
       " [738, 84, 900, 498],\n",
       " [738, 84, 900, 498, 452],\n",
       " [738, 84, 900, 498, 452, 4],\n",
       " [738, 84, 900, 498, 452, 4, 141],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33, 319],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33, 319, 1],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33, 319, 1, 293],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33, 319, 1, 293, 15],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33, 319, 1, 293, 15, 637],\n",
       " [738, 84, 900, 498, 452, 4, 141, 33, 319, 1, 293, 15, 637, 20],\n",
       " [87, 373],\n",
       " [87, 373, 1618],\n",
       " [87, 373, 1618, 1],\n",
       " [87, 373, 1618, 1, 1619],\n",
       " [87, 373, 1618, 1, 1619, 14],\n",
       " [87, 373, 1618, 1, 1619, 14, 83],\n",
       " [87, 373, 1618, 1, 1619, 14, 83, 2],\n",
       " [87, 373, 1618, 1, 1619, 14, 83, 2, 6],\n",
       " [87, 373, 1618, 1, 1619, 14, 83, 2, 6, 12],\n",
       " [87, 373, 1618, 1, 1619, 14, 83, 2, 6, 12, 174],\n",
       " [87, 373, 1618, 1, 1619, 14, 83, 2, 6, 12, 174, 349],\n",
       " [59, 12],\n",
       " [59, 12, 51],\n",
       " [59, 12, 51, 39],\n",
       " [59, 12, 51, 39, 901],\n",
       " [59, 12, 51, 39, 901, 29],\n",
       " [59, 12, 51, 39, 901, 29, 60],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16, 8],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16, 8, 275],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16, 8, 275, 740],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16, 8, 275, 740, 18],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16, 8, 275, 740, 18, 21],\n",
       " [59, 12, 51, 39, 901, 29, 60, 16, 8, 275, 740, 18, 21, 1],\n",
       " [143, 374],\n",
       " [143, 374, 2],\n",
       " [143, 374, 2, 28],\n",
       " [143, 374, 2, 28, 14],\n",
       " [143, 374, 2, 28, 14, 183],\n",
       " [143, 374, 2, 28, 14, 183, 53],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42, 37],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42, 37, 1],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42, 37, 1, 375],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42, 37, 1, 375, 7],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42, 37, 1, 375, 7, 1],\n",
       " [143, 374, 2, 28, 14, 183, 53, 4, 350, 42, 37, 1, 375, 7, 1, 1620],\n",
       " [35, 13],\n",
       " [35, 13, 43],\n",
       " [35, 13, 43, 255],\n",
       " [35, 13, 43, 255, 1621],\n",
       " [35, 13, 43, 255, 1621, 35],\n",
       " [35, 13, 43, 255, 1621, 35, 29],\n",
       " [35, 13, 43, 255, 1621, 35, 29, 638],\n",
       " [35, 13, 43, 255, 1621, 35, 29, 638, 1622],\n",
       " [35, 13, 43, 255, 1621, 35, 29, 638, 1622, 58],\n",
       " [35, 13, 43, 255, 1621, 35, 29, 638, 1622, 58, 1623],\n",
       " [35, 13, 43, 255, 1621, 35, 29, 638, 1622, 58, 1623, 2],\n",
       " [35, 13, 43, 255, 1621, 35, 29, 638, 1622, 58, 1623, 2, 3],\n",
       " [6, 211],\n",
       " [6, 211, 4],\n",
       " [6, 211, 4, 1624],\n",
       " [6, 211, 4, 1624, 16],\n",
       " [6, 211, 4, 1624, 16, 6],\n",
       " [6, 211, 4, 1624, 16, 6, 232],\n",
       " [6, 211, 4, 1624, 16, 6, 232, 499],\n",
       " [6, 211, 4, 1624, 16, 6, 232, 499, 1625],\n",
       " [6, 211, 4, 1624, 16, 6, 232, 499, 1625, 16],\n",
       " [6, 211, 4, 1624, 16, 6, 232, 499, 1625, 16, 233],\n",
       " [6, 211, 4, 1624, 16, 6, 232, 499, 1625, 16, 233, 1152],\n",
       " [274, 1],\n",
       " [274, 1, 256],\n",
       " [274, 1, 256, 57],\n",
       " [274, 1, 256, 57, 13],\n",
       " [274, 1, 256, 57, 13, 83],\n",
       " [274, 1, 256, 57, 13, 83, 13],\n",
       " [274, 1, 256, 57, 13, 83, 13, 52],\n",
       " [274, 1, 256, 57, 13, 83, 13, 52, 500],\n",
       " [274, 1, 256, 57, 13, 83, 13, 52, 500, 8],\n",
       " [274, 1, 256, 57, 13, 83, 13, 52, 500, 8, 73],\n",
       " [274, 1, 256, 57, 13, 83, 13, 52, 500, 8, 73, 37],\n",
       " [274, 1, 256, 57, 13, 83, 13, 52, 500, 8, 73, 37, 75],\n",
       " [1626, 30],\n",
       " [1626, 30, 741],\n",
       " [1626, 30, 741, 902],\n",
       " [1626, 30, 741, 902, 83],\n",
       " [1626, 30, 741, 902, 83, 64],\n",
       " [1626, 30, 741, 902, 83, 64, 24],\n",
       " [1626, 30, 741, 902, 83, 64, 24, 639],\n",
       " [1626, 30, 741, 902, 83, 64, 24, 639, 51],\n",
       " [1626, 30, 741, 902, 83, 64, 24, 639, 51, 498],\n",
       " [1626, 30, 741, 902, 83, 64, 24, 639, 51, 498, 102],\n",
       " [1626, 30, 741, 902, 83, 64, 24, 639, 51, 498, 102, 57],\n",
       " [1626, 30, 741, 902, 83, 64, 24, 639, 51, 498, 102, 57, 4],\n",
       " [350, 276],\n",
       " [350, 276, 14],\n",
       " [350, 276, 14, 183],\n",
       " [350, 276, 14, 183, 63],\n",
       " [350, 276, 14, 183, 63, 8],\n",
       " [350, 276, 14, 183, 63, 8, 567],\n",
       " [350, 276, 14, 183, 63, 8, 567, 38],\n",
       " [350, 276, 14, 183, 63, 8, 567, 38, 897],\n",
       " [350, 276, 14, 183, 63, 8, 567, 38, 897, 2],\n",
       " [36, 36],\n",
       " [36, 36, 36],\n",
       " [36, 36, 36, 59],\n",
       " [36, 36, 36, 59, 12],\n",
       " [36, 36, 36, 59, 12, 145],\n",
       " [36, 36, 36, 59, 12, 145, 351],\n",
       " [36, 36, 36, 59, 12, 145, 351, 4],\n",
       " [36, 36, 36, 59, 12, 145, 351, 4, 57],\n",
       " [36, 36, 36, 59, 12, 145, 351, 4, 57, 25],\n",
       " [36, 36, 36, 59, 12, 145, 351, 4, 57, 25, 10],\n",
       " [36, 36, 36, 59, 12, 145, 351, 4, 57, 25, 10, 175],\n",
       " [36, 36, 36, 59, 12, 145, 351, 4, 57, 25, 10, 175, 70],\n",
       " [242, 47],\n",
       " [242, 47, 1627],\n",
       " [242, 47, 1627, 742],\n",
       " [242, 47, 1627, 742, 64],\n",
       " [242, 47, 1627, 742, 64, 26],\n",
       " [242, 47, 1627, 742, 64, 26, 85],\n",
       " [242, 47, 1627, 742, 64, 26, 85, 4],\n",
       " [242, 47, 1627, 742, 64, 26, 85, 4, 640],\n",
       " [242, 47, 1627, 742, 64, 26, 85, 4, 640, 14],\n",
       " [242, 47, 1627, 742, 64, 26, 85, 4, 640, 14, 165],\n",
       " [242, 47, 1627, 742, 64, 26, 85, 4, 640, 14, 165, 83],\n",
       " [242, 47, 1627, 742, 64, 26, 85, 4, 640, 14, 165, 83, 2],\n",
       " [352, 12],\n",
       " [352, 12, 1],\n",
       " [352, 12, 1, 129],\n",
       " [352, 12, 1, 129, 31],\n",
       " [352, 12, 1, 129, 31, 903],\n",
       " [352, 12, 1, 129, 31, 903, 735],\n",
       " [352, 12, 1, 129, 31, 903, 735, 277],\n",
       " [352, 12, 1, 129, 31, 903, 735, 277, 17],\n",
       " [352, 12, 1, 129, 31, 903, 735, 277, 17, 1628],\n",
       " [352, 12, 1, 129, 31, 903, 735, 277, 17, 1628, 7],\n",
       " [352, 12, 1, 129, 31, 903, 735, 277, 17, 1628, 7, 1165],\n",
       " [352, 12, 1, 129, 31, 903, 735, 277, 17, 1628, 7, 1165, 18],\n",
       " [214, 60],\n",
       " [214, 60, 352],\n",
       " [214, 60, 352, 76],\n",
       " [214, 60, 352, 76, 158],\n",
       " [214, 60, 352, 76, 158, 14],\n",
       " [214, 60, 352, 76, 158, 14, 196],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36, 95],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36, 95, 20],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36, 95, 20, 64],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36, 95, 20, 64, 59],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36, 95, 20, 64, 59, 98],\n",
       " [214, 60, 352, 76, 158, 14, 196, 13, 45, 36, 95, 20, 64, 59, 98, 51],\n",
       " [743, 11],\n",
       " [743, 11, 1],\n",
       " [743, 11, 1, 256],\n",
       " [743, 11, 1, 256, 119],\n",
       " [743, 11, 1, 256, 119, 320],\n",
       " [743, 11, 1, 256, 119, 320, 28],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160, 904],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160, 904, 5],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160, 904, 5, 905],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160, 904, 5, 905, 3],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160, 904, 5, 905, 3, 225],\n",
       " [743, 11, 1, 256, 119, 320, 28, 13, 160, 904, 5, 905, 3, 225, 26],\n",
       " [44, 5],\n",
       " [44, 5, 108],\n",
       " [44, 5, 108, 13],\n",
       " [44, 5, 108, 13, 43],\n",
       " [44, 5, 108, 13, 43, 28],\n",
       " [44, 5, 108, 13, 43, 28, 57],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744, 14],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744, 14, 222],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744, 14, 222, 2],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744, 14, 222, 2, 3],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744, 14, 222, 2, 3, 95],\n",
       " [44, 5, 108, 13, 43, 28, 57, 294, 234, 744, 14, 222, 2, 3, 95, 10],\n",
       " [70, 4],\n",
       " [70, 4, 105],\n",
       " [70, 4, 105, 174],\n",
       " [70, 4, 105, 174, 630],\n",
       " [70, 4, 105, 174, 630, 3],\n",
       " [70, 4, 105, 174, 630, 3, 46],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19, 257],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19, 257, 4],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19, 257, 4, 48],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19, 257, 4, 48, 11],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19, 257, 4, 48, 11, 5],\n",
       " [70, 4, 105, 174, 630, 3, 46, 19, 257, 4, 48, 11, 5, 1629],\n",
       " [205, 7],\n",
       " [205, 7, 74],\n",
       " [205, 7, 74, 453],\n",
       " [205, 7, 74, 453, 294],\n",
       " [205, 7, 74, 453, 294, 234],\n",
       " [205, 7, 74, 453, 294, 234, 744],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294, 234],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294, 234, 744],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294, 234, 744, 2],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294, 234, 744, 2, 3],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294, 234, 744, 2, 3, 641],\n",
       " [205, 7, 74, 453, 294, 234, 744, 57, 294, 234, 744, 2, 3, 641, 453],\n",
       " [744, 234],\n",
       " [744, 234, 294],\n",
       " [744, 234, 294, 2],\n",
       " [744, 234, 294, 2, 24],\n",
       " [744, 234, 294, 2, 24, 13],\n",
       " [744, 234, 294, 2, 24, 13, 63],\n",
       " [744, 234, 294, 2, 24, 13, 63, 16],\n",
       " [744, 234, 294, 2, 24, 13, 63, 16, 6],\n",
       " [744, 234, 294, 2, 24, 13, 63, 16, 6, 409],\n",
       " [744, 234, 294, 2, 24, 13, 63, 16, 6, 409, 410],\n",
       " [744, 234, 294, 2, 24, 13, 63, 16, 6, 409, 410, 407],\n",
       " [744, 234, 294, 2, 24, 13, 63, 16, 6, 409, 410, 407, 235],\n",
       " [8, 275],\n",
       " [8, 275, 85],\n",
       " [8, 275, 85, 411],\n",
       " [8, 275, 85, 411, 103],\n",
       " [8, 275, 85, 411, 103, 74],\n",
       " [8, 275, 85, 411, 103, 74, 6],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8, 6],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8, 6, 185],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8, 6, 185, 15],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8, 6, 185, 15, 6],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8, 6, 185, 15, 6, 12],\n",
       " [8, 275, 85, 411, 103, 74, 6, 140, 8, 6, 185, 15, 6, 12, 1630],\n",
       " [65, 3],\n",
       " [65, 3, 22],\n",
       " [65, 3, 22, 91],\n",
       " [65, 3, 22, 91, 501],\n",
       " [65, 3, 22, 91, 501, 4],\n",
       " [65, 3, 22, 91, 501, 4, 502],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6, 12],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6, 12, 642],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6, 12, 642, 206],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6, 12, 642, 206, 11],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6, 12, 642, 206, 11, 206],\n",
       " [65, 3, 22, 91, 501, 4, 502, 15, 6, 12, 642, 206, 11, 206, 20],\n",
       " [352, 3],\n",
       " [352, 3, 257],\n",
       " [352, 3, 257, 4],\n",
       " [352, 3, 257, 4, 17],\n",
       " [352, 3, 257, 4, 17, 26],\n",
       " [352, 3, 257, 4, 17, 26, 1166],\n",
       " [352, 3, 257, 4, 17, 26, 1166, 376],\n",
       " [352, 3, 257, 4, 17, 26, 1166, 376, 352],\n",
       " [352, 3, 257, 4, 17, 26, 1166, 376, 352, 156],\n",
       " [352, 3, 257, 4, 17, 26, 1166, 376, 352, 156, 64],\n",
       " [352, 3, 257, 4, 17, 26, 1166, 376, 352, 156, 64, 1],\n",
       " [352, 3, 257, 4, 17, 26, 1166, 376, 352, 156, 64, 1, 1631],\n",
       " [67, 13],\n",
       " [67, 13, 197],\n",
       " [67, 13, 197, 234],\n",
       " [67, 13, 197, 234, 5],\n",
       " [67, 13, 197, 234, 5, 905],\n",
       " [67, 13, 197, 234, 5, 905, 2],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290, 1167],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290, 1167, 1167],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290, 1167, 1167, 36],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290, 1167, 1167, 36, 6],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290, 1167, 1167, 36, 6, 114],\n",
       " [67, 13, 197, 234, 5, 905, 2, 56, 290, 1167, 1167, 36, 6, 114, 170],\n",
       " [5, 1632],\n",
       " [5, 1632, 7],\n",
       " [5, 1632, 7, 1633],\n",
       " [5, 1632, 7, 1633, 3],\n",
       " [5, 1632, 7, 1633, 3, 454],\n",
       " [5, 1632, 7, 1633, 3, 454, 568],\n",
       " [5, 1632, 7, 1633, 3, 454, 568, 3],\n",
       " [5, 1632, 7, 1633, 3, 454, 568, 3, 1],\n",
       " [5, 1632, 7, 1633, 3, 454, 568, 3, 1, 496],\n",
       " [5, 1632, 7, 1633, 3, 454, 568, 3, 1, 496, 12],\n",
       " [5, 1632, 7, 1633, 3, 454, 568, 3, 1, 496, 12, 113],\n",
       " [10, 12],\n",
       " [10, 12, 27],\n",
       " [10, 12, 27, 5],\n",
       " [10, 12, 27, 5, 243],\n",
       " [10, 12, 27, 5, 243, 906],\n",
       " [10, 12, 27, 5, 243, 906, 3],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19, 4],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19, 4, 17],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19, 4, 17, 210],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19, 4, 17, 210, 11],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19, 4, 17, 210, 11, 5],\n",
       " [10, 12, 27, 5, 243, 906, 3, 6, 569, 38, 19, 4, 17, 210, 11, 5, 155],\n",
       " [6, 101],\n",
       " [6, 101, 38],\n",
       " [6, 101, 38, 28],\n",
       " [6, 101, 38, 28, 8],\n",
       " [6, 101, 38, 28, 8, 12],\n",
       " [6, 101, 38, 28, 8, 12, 21],\n",
       " [6, 101, 38, 28, 8, 12, 21, 892],\n",
       " [6, 101, 38, 28, 8, 12, 21, 892, 1634],\n",
       " [6, 101, 38, 28, 8, 12, 21, 892, 1634, 123],\n",
       " [6, 101, 38, 28, 8, 12, 21, 892, 1634, 123, 17],\n",
       " [6, 101, 38, 28, 8, 12, 21, 892, 1634, 123, 17, 12],\n",
       " [6, 101, 38, 28, 8, 12, 21, 892, 1634, 123, 17, 12, 193],\n",
       " [138, 745],\n",
       " [138, 745, 3],\n",
       " [138, 745, 3, 1],\n",
       " [138, 745, 3, 1, 147],\n",
       " [138, 745, 3, 1, 147, 99],\n",
       " [138, 745, 3, 1, 147, 99, 12],\n",
       " [138, 745, 3, 1, 147, 99, 12, 292],\n",
       " [138, 745, 3, 1, 147, 99, 12, 292, 11],\n",
       " [138, 745, 3, 1, 147, 99, 12, 292, 11, 377],\n",
       " [138, 745, 3, 1, 147, 99, 12, 292, 11, 377, 1635],\n",
       " [138, 745, 3, 1, 147, 99, 12, 292, 11, 377, 1635, 36],\n",
       " [138, 745, 3, 1, 147, 99, 12, 292, 11, 377, 1635, 36, 8],\n",
       " [59, 12],\n",
       " [59, 12, 27],\n",
       " [59, 12, 27, 5],\n",
       " [59, 12, 27, 5, 155],\n",
       " [59, 12, 27, 5, 155, 4],\n",
       " [59, 12, 27, 5, 155, 4, 23],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176, 46],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176, 46, 10],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176, 46, 10, 44],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176, 46, 10, 44, 1],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176, 46, 10, 44, 1, 1168],\n",
       " [59, 12, 27, 5, 155, 4, 23, 907, 176, 46, 10, 44, 1, 1168, 3],\n",
       " [12, 91],\n",
       " [12, 91, 11],\n",
       " [12, 91, 11, 60],\n",
       " [12, 91, 11, 60, 4],\n",
       " [12, 91, 11, 60, 4, 269],\n",
       " [12, 91, 11, 60, 4, 269, 8],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8, 244],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8, 244, 5],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8, 244, 5, 746],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8, 244, 5, 746, 182],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8, 244, 5, 746, 182, 76],\n",
       " [12, 91, 11, 60, 4, 269, 8, 86, 16, 8, 244, 5, 746, 182, 76, 643],\n",
       " [3, 908],\n",
       " [3, 908, 84],\n",
       " [3, 908, 84, 563],\n",
       " [3, 908, 84, 563, 134],\n",
       " [3, 908, 84, 563, 134, 191],\n",
       " [3, 908, 84, 563, 134, 191, 2],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6, 12],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6, 12, 291],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6, 12, 291, 295],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6, 12, 291, 295, 8],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6, 12, 291, 295, 8, 56],\n",
       " [3, 908, 84, 563, 134, 191, 2, 6, 12, 291, 295, 8, 56, 6],\n",
       " [244, 1],\n",
       " [244, 1, 746],\n",
       " [244, 1, 746, 28],\n",
       " [244, 1, 746, 28, 1],\n",
       " [244, 1, 746, 28, 1, 99],\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5455049c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad sequences\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f454f82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,  315,  490],\n",
       "       [   0,    0,    0, ...,  315,  490,   11],\n",
       "       [   0,    0,    0, ...,  490,   11,  886],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    3,    1, 2857],\n",
       "       [   0,    0,    0, ...,    1, 2857, 1563],\n",
       "       [   0,    0,    0, ..., 2857, 1563,  846]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences=np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42faafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create predictors and label\n",
    "import tensorflow as tf\n",
    "x, y = input_sequences[:, :-1], input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68854541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,  315],\n",
       "       [   0,    0,    0, ...,    0,  315,  490],\n",
       "       [   0,    0,    0, ...,  315,  490,   11],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  328,    3,    1],\n",
       "       [   0,    0,    0, ...,    3,    1, 2857],\n",
       "       [   0,    0,    0, ...,    1, 2857, 1563]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28290790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 490,   11,  886, ..., 2857, 1563,  846], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c07b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30113c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220922c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyanshu\\coding\\python_projects\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">285,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2858</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">288,658</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m285,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2858\u001b[0m)           │       \u001b[38;5;34m288,658\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">825,458</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m825,458\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">825,458</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m825,458\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train our LSTM RNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "\n",
    "## Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "## Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_sequence_length))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461b077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyanshu\\coding\\python_projects\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">113,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">486,618</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m481,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m113,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m75,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)           │       \u001b[38;5;34m486,618\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,157,418</span> (4.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,157,418\u001b[0m (4.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,157,418</span> (4.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,157,418\u001b[0m (4.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train our GRU RNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "\n",
    "## GRU RNN\n",
    "## Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(GRU(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "## Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_sequence_length))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f36abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.7130 - loss: 1.1219 - val_accuracy: 0.1261 - val_loss: 10.8873\n",
      "Epoch 2/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.7149 - loss: 1.1149 - val_accuracy: 0.1275 - val_loss: 10.9516\n",
      "Epoch 3/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7210 - loss: 1.0963 - val_accuracy: 0.1279 - val_loss: 10.9699\n",
      "Epoch 4/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7184 - loss: 1.0928 - val_accuracy: 0.1303 - val_loss: 11.0044\n",
      "Epoch 5/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7219 - loss: 1.0821 - val_accuracy: 0.1289 - val_loss: 11.0838\n",
      "Epoch 6/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7228 - loss: 1.0757 - val_accuracy: 0.1299 - val_loss: 11.0679\n",
      "Epoch 7/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7297 - loss: 1.0641 - val_accuracy: 0.1279 - val_loss: 11.1239\n",
      "Epoch 8/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7334 - loss: 1.0473 - val_accuracy: 0.1273 - val_loss: 11.1375\n",
      "Epoch 9/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7316 - loss: 1.0398 - val_accuracy: 0.1306 - val_loss: 11.1641\n",
      "Epoch 10/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7322 - loss: 1.0359 - val_accuracy: 0.1310 - val_loss: 11.1741\n",
      "Epoch 11/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.7388 - loss: 1.0223 - val_accuracy: 0.1303 - val_loss: 11.2558\n",
      "Epoch 12/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7370 - loss: 1.0140 - val_accuracy: 0.1291 - val_loss: 11.2772\n",
      "Epoch 13/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.7435 - loss: 0.9976 - val_accuracy: 0.1281 - val_loss: 11.2777\n",
      "Epoch 14/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7438 - loss: 0.9945 - val_accuracy: 0.1247 - val_loss: 11.3182\n",
      "Epoch 15/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7496 - loss: 0.9814 - val_accuracy: 0.1285 - val_loss: 11.3355\n",
      "Epoch 16/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7473 - loss: 0.9752 - val_accuracy: 0.1273 - val_loss: 11.4088\n",
      "Epoch 17/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7560 - loss: 0.9577 - val_accuracy: 0.1303 - val_loss: 11.4319\n",
      "Epoch 18/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7532 - loss: 0.9484 - val_accuracy: 0.1269 - val_loss: 11.4957\n",
      "Epoch 19/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7512 - loss: 0.9524 - val_accuracy: 0.1235 - val_loss: 11.5367\n",
      "Epoch 20/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7587 - loss: 0.9307 - val_accuracy: 0.1283 - val_loss: 11.5768\n",
      "Epoch 21/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7603 - loss: 0.9264 - val_accuracy: 0.1275 - val_loss: 11.5394\n",
      "Epoch 22/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7556 - loss: 0.9254 - val_accuracy: 0.1283 - val_loss: 11.5904\n",
      "Epoch 23/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7634 - loss: 0.9162 - val_accuracy: 0.1228 - val_loss: 11.6372\n",
      "Epoch 24/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7651 - loss: 0.9072 - val_accuracy: 0.1261 - val_loss: 11.6694\n",
      "Epoch 25/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7713 - loss: 0.8943 - val_accuracy: 0.1261 - val_loss: 11.7115\n",
      "Epoch 26/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.7688 - loss: 0.8874 - val_accuracy: 0.1265 - val_loss: 11.7010\n",
      "Epoch 27/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7706 - loss: 0.8818 - val_accuracy: 0.1247 - val_loss: 11.7782\n",
      "Epoch 28/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7783 - loss: 0.8629 - val_accuracy: 0.1267 - val_loss: 11.7947\n",
      "Epoch 29/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7741 - loss: 0.8747 - val_accuracy: 0.1222 - val_loss: 11.8522\n",
      "Epoch 30/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7772 - loss: 0.8574 - val_accuracy: 0.1275 - val_loss: 11.8469\n",
      "Epoch 31/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7799 - loss: 0.8486 - val_accuracy: 0.1299 - val_loss: 11.8768\n",
      "Epoch 32/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7797 - loss: 0.8442 - val_accuracy: 0.1224 - val_loss: 11.9080\n",
      "Epoch 33/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 245ms/step - accuracy: 0.7794 - loss: 0.8455 - val_accuracy: 0.1253 - val_loss: 11.9284\n",
      "Epoch 34/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.7790 - loss: 0.8358 - val_accuracy: 0.1253 - val_loss: 11.9554\n",
      "Epoch 35/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7874 - loss: 0.8183 - val_accuracy: 0.1275 - val_loss: 12.0108\n",
      "Epoch 36/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7890 - loss: 0.8117 - val_accuracy: 0.1303 - val_loss: 12.0277\n",
      "Epoch 37/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7903 - loss: 0.8072 - val_accuracy: 0.1265 - val_loss: 12.0408\n",
      "Epoch 38/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7902 - loss: 0.8019 - val_accuracy: 0.1261 - val_loss: 12.0560\n",
      "Epoch 39/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.7924 - loss: 0.7971 - val_accuracy: 0.1281 - val_loss: 12.0983\n",
      "Epoch 40/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7888 - loss: 0.7907 - val_accuracy: 0.1230 - val_loss: 12.0777\n",
      "Epoch 41/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7964 - loss: 0.7800 - val_accuracy: 0.1285 - val_loss: 12.1656\n",
      "Epoch 42/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7987 - loss: 0.7705 - val_accuracy: 0.1243 - val_loss: 12.1528\n",
      "Epoch 43/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7996 - loss: 0.7677 - val_accuracy: 0.1269 - val_loss: 12.2205\n",
      "Epoch 44/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7974 - loss: 0.7715 - val_accuracy: 0.1257 - val_loss: 12.2572\n",
      "Epoch 45/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7992 - loss: 0.7627 - val_accuracy: 0.1233 - val_loss: 12.2553\n",
      "Epoch 46/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8043 - loss: 0.7498 - val_accuracy: 0.1226 - val_loss: 12.2866\n",
      "Epoch 47/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8082 - loss: 0.7448 - val_accuracy: 0.1220 - val_loss: 12.3157\n",
      "Epoch 48/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8040 - loss: 0.7405 - val_accuracy: 0.1200 - val_loss: 12.3556\n",
      "Epoch 49/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 768ms/step - accuracy: 0.8045 - loss: 0.7414 - val_accuracy: 0.1216 - val_loss: 12.3687\n",
      "Epoch 50/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8071 - loss: 0.7267 - val_accuracy: 0.1224 - val_loss: 12.3915\n",
      "Epoch 51/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8127 - loss: 0.7239 - val_accuracy: 0.1208 - val_loss: 12.3908\n",
      "Epoch 52/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8148 - loss: 0.7101 - val_accuracy: 0.1255 - val_loss: 12.4822\n",
      "Epoch 53/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8108 - loss: 0.7205 - val_accuracy: 0.1239 - val_loss: 12.4066\n",
      "Epoch 54/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8093 - loss: 0.7160 - val_accuracy: 0.1243 - val_loss: 12.4353\n",
      "Epoch 55/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8135 - loss: 0.7100 - val_accuracy: 0.1231 - val_loss: 12.5146\n",
      "Epoch 56/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8201 - loss: 0.6921 - val_accuracy: 0.1231 - val_loss: 12.5492\n",
      "Epoch 57/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8108 - loss: 0.7085 - val_accuracy: 0.1241 - val_loss: 12.5541\n",
      "Epoch 58/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8202 - loss: 0.6855 - val_accuracy: 0.1253 - val_loss: 12.5693\n",
      "Epoch 59/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8178 - loss: 0.6931 - val_accuracy: 0.1216 - val_loss: 12.6540\n",
      "Epoch 60/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8201 - loss: 0.6784 - val_accuracy: 0.1218 - val_loss: 12.6588\n",
      "Epoch 61/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.8223 - loss: 0.6738 - val_accuracy: 0.1230 - val_loss: 12.6098\n",
      "Epoch 62/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.8226 - loss: 0.6697 - val_accuracy: 0.1224 - val_loss: 12.6793\n",
      "Epoch 63/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8233 - loss: 0.6670 - val_accuracy: 0.1208 - val_loss: 12.6933\n",
      "Epoch 64/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.8260 - loss: 0.6654 - val_accuracy: 0.1192 - val_loss: 12.7916\n",
      "Epoch 65/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.8256 - loss: 0.6565 - val_accuracy: 0.1206 - val_loss: 12.7497\n",
      "Epoch 66/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.8204 - loss: 0.6663 - val_accuracy: 0.1210 - val_loss: 12.7255\n",
      "Epoch 67/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8302 - loss: 0.6529 - val_accuracy: 0.1178 - val_loss: 12.7453\n",
      "Epoch 68/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8297 - loss: 0.6434 - val_accuracy: 0.1206 - val_loss: 12.8418\n",
      "Epoch 69/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8298 - loss: 0.6405 - val_accuracy: 0.1212 - val_loss: 12.8218\n",
      "Epoch 70/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8310 - loss: 0.6394 - val_accuracy: 0.1200 - val_loss: 12.8826\n",
      "Epoch 71/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8307 - loss: 0.6373 - val_accuracy: 0.1228 - val_loss: 12.8995\n",
      "Epoch 72/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8305 - loss: 0.6320 - val_accuracy: 0.1208 - val_loss: 12.9359\n",
      "Epoch 73/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8346 - loss: 0.6248 - val_accuracy: 0.1218 - val_loss: 12.9659\n",
      "Epoch 74/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8364 - loss: 0.6177 - val_accuracy: 0.1228 - val_loss: 12.9700\n",
      "Epoch 75/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8364 - loss: 0.6111 - val_accuracy: 0.1180 - val_loss: 12.9932\n",
      "Epoch 76/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8322 - loss: 0.6200 - val_accuracy: 0.1228 - val_loss: 12.9877\n",
      "Epoch 77/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8382 - loss: 0.6055 - val_accuracy: 0.1206 - val_loss: 13.0469\n",
      "Epoch 78/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8364 - loss: 0.6033 - val_accuracy: 0.1212 - val_loss: 13.0672\n",
      "Epoch 79/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8363 - loss: 0.6117 - val_accuracy: 0.1263 - val_loss: 13.0913\n",
      "Epoch 80/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8377 - loss: 0.6040 - val_accuracy: 0.1216 - val_loss: 13.0870\n",
      "Epoch 81/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8411 - loss: 0.5950 - val_accuracy: 0.1190 - val_loss: 13.1506\n",
      "Epoch 82/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8417 - loss: 0.5937 - val_accuracy: 0.1231 - val_loss: 13.1282\n",
      "Epoch 83/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8430 - loss: 0.5891 - val_accuracy: 0.1269 - val_loss: 13.1651\n",
      "Epoch 84/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.5865 - val_accuracy: 0.1188 - val_loss: 13.1532\n",
      "Epoch 85/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8438 - loss: 0.5778 - val_accuracy: 0.1237 - val_loss: 13.2105\n",
      "Epoch 86/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8419 - loss: 0.5912 - val_accuracy: 0.1178 - val_loss: 13.2283\n",
      "Epoch 87/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8469 - loss: 0.5767 - val_accuracy: 0.1218 - val_loss: 13.2246\n",
      "Epoch 88/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8417 - loss: 0.5749 - val_accuracy: 0.1172 - val_loss: 13.2864\n",
      "Epoch 89/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8470 - loss: 0.5714 - val_accuracy: 0.1202 - val_loss: 13.2792\n",
      "Epoch 90/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8465 - loss: 0.5695 - val_accuracy: 0.1214 - val_loss: 13.3284\n",
      "Epoch 91/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8472 - loss: 0.5609 - val_accuracy: 0.1162 - val_loss: 13.3854\n",
      "Epoch 92/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8488 - loss: 0.5624 - val_accuracy: 0.1194 - val_loss: 13.3479\n",
      "Epoch 93/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8500 - loss: 0.5586 - val_accuracy: 0.1204 - val_loss: 13.3723\n",
      "Epoch 94/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8528 - loss: 0.5562 - val_accuracy: 0.1184 - val_loss: 13.3927\n",
      "Epoch 95/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8474 - loss: 0.5554 - val_accuracy: 0.1192 - val_loss: 13.4071\n",
      "Epoch 96/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8490 - loss: 0.5573 - val_accuracy: 0.1158 - val_loss: 13.4218\n",
      "Epoch 97/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8537 - loss: 0.5417 - val_accuracy: 0.1196 - val_loss: 13.4491\n",
      "Epoch 98/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8512 - loss: 0.5536 - val_accuracy: 0.1206 - val_loss: 13.4696\n",
      "Epoch 99/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8517 - loss: 0.5477 - val_accuracy: 0.1222 - val_loss: 13.4670\n",
      "Epoch 100/100\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8552 - loss: 0.5341 - val_accuracy: 0.1271 - val_loss: 13.4849\n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "history = model.fit(x_train, y_train, epochs=100,validation_data=(x_test, y_test),verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f70a948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to predict the next word\n",
    "def predict_next_word(model, tokenizer, text, max_sequence_length):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    if len(token_list) >= max_sequence_length:\n",
    "        token_list = token_list[-(max_sequence_length-1):]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e2cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: ALL PERSONS MORE THAN A MILE HIGH TO LEAVE THE\n",
      "Next word prediction: court\n"
     ]
    }
   ],
   "source": [
    "input_text = \"ALL PERSONS MORE THAN A MILE HIGH TO LEAVE THE\"\n",
    "print(f\"Input text: {input_text}\")\n",
    "max_sequence_length= model.input_shape[1]+1\n",
    "next_word = predict_next_word(model, tokenizer, input_text, max_sequence_length)\n",
    "print(f\"Next word prediction: {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c3977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "##Save the model\n",
    "model.save('Next_word_lstm.h5')\n",
    "##Save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
